<dl class="thr_top restitle_sticky">
            <dt class="titleheader">
                <span class="thr_id"><a href="#pos_box" title="NO.12256471(スレ主)へ返信" onclick="TextBox1 = document.directForm.body;val=TextBox1.value;TextBox1.value=val+&quot;>>0\n&quot;">NO.12256471</a></span>
                <span class="posts" itemprop="datePublished">2024/08/10 10:29</span>

                                <div class="delbtn_wrap __in_res"></div>                <br>
                <div class="title_thr_wrap "><div id="title_thr"><strong class="thr_status_icon" itemprop="headline" content="北京原人" title="北京原人">北京原人</strong></div></div>
            </dt>
            								        </dl>具体时间在这里<span class="posts" itemprop="datePublished">2024/08/10 10:29</span>     <li data-tid="12256471">
                                            <span class="thrNumber">1</span>
                    					                    <a href="/thr_res/acode=13/ctrid=1/ctgid=150/bid=2396/tid=12256471/tp=1/" class="thr_status_icon" title="北京原人">
                                                北京原人
                    </a>
					<span class="thrListContent">
											<span class="thr-posted-ago">
													3時間前												</span>
																<span class="chart_count_area">
							<span class="thrlis_chart_space"><i class="fa fa-bar-chart" aria-hidden="true"></i>
								<span class="chart_balloon newslis_count">閲覧数</span>
							</span>
							<span>4856</span>
						</span>
						<span class="comment_count_area newslis_count">
							<span class="thrlis_comment_space"><i class="fa fa-comment-o" aria-hidden="true"></i>
								<span class="comment_balloon newslis_count">レス数</span>
							</span>
							<span>299</span>
						</span>
										</span>
										                                        
				</li>列表一个帖子的代码，点进去<dl id="thr_top">
            <dd class="body"><div id="threadBody" itemprop="articlebody">早く人間になりなさい<!-- pc api連携なし --></div></dd><div class="author_shoppr_wrap"><dd class="name " itemprop="author" itemscope="" itemtype="http://schema.org/Person">[<span>匿名さん</span>] </dd><div class="repo_good_wrap"><div class="repo_imp_wrap"><a href="/thr_repo02/acode=13/ctrid=1/ctgid=150/bid=2396/tid=12256471/p=1/" style="margin-left:15px" class="thr_repo_link"><img width="15" height="15" src="https://img2.bakusai.com/p/img/icons/repo.svg">報告</a><span class="thrListContent"><span class="chart_count_area"><span class="reslis_chart_space cha_margin_adj"><i class="fa fa-bar-chart" aria-hidden="true"></i><span class="chart_balloon ballchaposi">閲覧数</span></span><span>4857</span></span><span class="comment_count_area"><span class="reslis_comment_space com_margin_adj"><i class="fa fa-comment-o" aria-hidden="true"></i><span class="comment_balloon ballcomposi">レス数</span></span><span>299</span></span></span></div><!-- スレ用 -->
<span class="rating_good_bad good_bad_Thr notLogin">
  <span class="good_bad_totla">合計：</span>
  <button class="good_Button gb_total pushed" type="button" name="button">
    <span class="good_Thumbs gb_total"><i class="fa fa-thumbs-o-up animated-hover" aria-hidden="true"></i></span>
    <span class="good_bad_loading gb_total"><img src="https://img2.bakusai.com/p/img/loading/ring.gif"></span>
    <span class="good_counter gb_total">0</span>
    <span class="good_balloon">Good!</span>
  </button>
  <button class="bad_Button gb_total pushed" type="button" name="button">
    <span class="bad_Thumbs gb_total"><i class="fa fa-thumbs-o-down animated-hover" aria-hidden="true"></i></span>
    <span class="good_bad_loading gb_total"><img src="https://img2.bakusai.com/p/img/loading/ring.gif"></span>
    <span class="bad_counter gb_total">0</span>
    <span class="bad_balloon">Bad</span>
  </button>
</span>
</div></div>        </dl>其中<div id="threadBody" itemprop="articlebody">早く人間になりなさい是帖子内容，<div class="article res_list_article " itemscope="" itemtype="http://schema.org/UserComments" id="res250"><hr><dt><div class="res_meta_wrap"><span class="resnumb"><a href="#pos_box" title="#250へ返信" onclick="TextBox1 = document.directForm.body;val=TextBox1.value;TextBox1.value=val+&quot;>>250\n&quot;">#250</a></span> <span itemprop="commentTime">2025/11/29 08:37</span></div></dt><dd class="body "><div class="resbody" itemprop="commentText">富裕層は国外逃亡、残った貧困層も中央政府と戦う覚悟も無く、習近平は日本を人民のガス抜きの材料にして誤魔化している。眠れる獅子は眠ったまま朽ち果てるのだ。</div><br><div class="clear"></div></dd><div class="name_goodbad_box"><span class="name-wapper"><dd class="name">[匿名さん]</dd></span><!-- レス用 -->
<div class="rating_good_bad good_bad_Res notLogin">
  <button class="good_Button" type="button" name="button">
    <span class="good_Thumbs"><i class="fa fa-thumbs-o-up animated-hover" aria-hidden="true"></i></span>
    <span class="good_bad_loading"><img src="https://img2.bakusai.com/p/img/loading/ring.gif"></span>
    <span class="good_counter">0</span>
    <span class="good_balloon">Good!</span>
  </button>
  <button class="bad_Button" type="button" name="button">
    <span class="bad_Thumbs"><i class="fa fa-thumbs-o-down animated-hover" aria-hidden="true"></i></span>
    <span class="good_bad_loading"><img src="https://img2.bakusai.com/p/img/loading/ring.gif"></span>
    <span class="bad_counter">0</span>
    <span class="bad_balloon">Bad</span>
  </button>
</div>
</div></div>其中<div class="resbody" itemprop="commentText">富裕層は国外逃亡、残った貧困層も中央政府と戦う覚悟も無く、習近平は日本を人民のガス抜きの材料にして誤魔化している。眠れる獅子は眠ったまま朽ち果てるのだ是一条评论的内容






要完整python代码，抓取从https://bakusai.com/thr_tl/acode=13/ctrid=1/ctgid=150/bid=2396/p=1/开始，p=2,p=3依次往下爬，直到最后回复时间不是系统时间所在月份为止，判断帖子最后回复时间可以从<span class="thr-posted-ago"> 3時間前 </span>里找


成功的代码
import requests import time import json from datetime import datetime from lxml import etree # ================== 基础配置 ================== BASE_URL = "https://bakusai.com" LIST_URL = "https://bakusai.com/thr_tl/acode=13/ctrid=1/ctgid=150/bid=2396/p={}/" HEADERS = { "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)", "Accept-Language": "ja-JP,ja;q=0.9" } session = requests.Session() session.headers.update(HEADERS) # ================== 工具函数 ================== def fetch_html(url, retries=3): for i in range(retries): try: r = session.get(url, timeout=20) r.raise_for_status() r.encoding = "utf-8" return r.text except Exception as e: print(f"⚠️ 请求失败，第 {i+1} 次重试：{e}") time.sleep(3) return None def parse_jp_datetime(text): """ 2024/08/10 10:29 """ return datetime.strptime(text.strip(), "%Y/%m/%d %H:%M") # ================== 1️⃣ 解析列表页 ================== def parse_thread_list(page): url = LIST_URL.format(page) html = fetch_html(url) if not html: return [] tree = etree.HTML(html.encode("utf-8")) threads = [] li_nodes = tree.xpath('//li[@data-tid]') for li in li_nodes: tid = li.attrib.get("data-tid") title = li.xpath('.//a[contains(@class,"thr_status_icon")]/text()') title = title[0].strip() if title else "" comment = li.xpath('.//span[contains(@class,"comment_count_area")]/span[last()]/text()') comment_count = int(comment[0]) if comment and comment[0].isdigit() else 0 if comment_count > 0: threads.append({ "tid": tid, "title": title, "comment_count": comment_count }) print(f" ✔ 本页解析到 {len(threads)} 个有回复帖子") return threads # ================== 2️⃣ 解析帖子页 ================== def parse_thread_detail(tid): url = f"{BASE_URL}/thr_res/acode=13/ctrid=1/ctgid=150/bid=2396/tid={tid}/tp=1/" html = fetch_html(url) if not html: return None tree = etree.HTML(html.encode("utf-8")) # 标题 title = tree.xpath('//div[@id="title_thr"]/strong/text()') title = title[0].strip() if title else "" # 发布时间 post_time_raw = tree.xpath('//span[@class="posts"]/text()') if not post_time_raw: return None post_time = parse_jp_datetime(post_time_raw[0]) # 正文 body = tree.xpath('//div[@id="threadBody"]/text()') body = body[0].strip() if body else "" # 评论 comments = [] res_nodes = tree.xpath('//div[contains(@class,"res_list_article")]') for res in res_nodes: text = res.xpath('.//div[@class="resbody"]/text()') time_text = res.xpath('.//span[@itemprop="commentTime"]/text()') if text and time_text: comments.append({ "time": time_text[0].strip(), "content": text[0].strip() }) return { "tid": tid, "title": title, "post_time": post_time.strftime("%Y-%m-%d %H:%M"), "body": body, "comments": comments } # ================== 3️⃣ 主流程：只抓 12 月 ================== def crawl_december(max_pages=5): results = [] for page in range(1, max_pages + 1): print(f"📄 正在抓列表页 {page}") threads = parse_thread_list(page) if not threads: print("⚠️ 本页无帖子，跳过") continue for t in threads: detail = parse_thread_detail(t["tid"]) if not detail: continue month = datetime.strptime(detail["post_time"], "%Y-%m-%d %H:%M").month if month != 12: continue print(f" ✅ 收录 12 月帖子 {t['tid']}（{len(detail['comments'])} 评论）") results.append(detail) time.sleep(1.5) # 防封 time.sleep(3) return results # ================== 4️⃣ 程序入口 ================== if __name__ == "__main__": data = crawl_december(max_pages=5) with open("bakusai_december.json", "w", encoding="utf-8") as f: json.dump(data, f, ensure_ascii=False, indent=2) print(f"\n🎉 完成：共抓取 {len(data)} 条 12 月帖子") print("📁 已输出文件：bakusai_december.json")

import requests
import time
import json
from datetime import datetime
from lxml import etree

BASE_URL = "https://bakusai.com"
LIST_URL = "https://bakusai.com/thr_tl/acode=13/ctrid=1/ctgid=150/bid=2396/p={}/"

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
    "Accept-Language": "ja-JP,ja;q=0.9"
}

session = requests.Session()
session.headers.update(HEADERS)


def fetch(url):
    try:
        r = session.get(url, timeout=20)
        r.raise_for_status()
        return r.content  # bytes，防止 encoding 报错
    except Exception as e:
        print("⚠️ 请求失败：", e)
        return None


def parse_time(s):
    try:
        return datetime.strptime(s.strip(), "%Y/%m/%d %H:%M")
    except:
        return None


# ========== 列表页 ==========
def parse_thread_list(page):
    print(f"📄 正在抓列表页 {page}")
    html = fetch(LIST_URL.format(page))
    if not html:
        return []

    tree = etree.HTML(html)
    threads = []

    for li in tree.xpath("//li[@data-tid]"):
        tid = li.get("data-tid")

        title = "".join(
            li.xpath(".//a[contains(@class,'thr_status_icon')]//text()")
        ).strip()

        # ⭐ 修正后的评论数 XPath
        reply_text = "".join(
            li.xpath(".//span[contains(@class,'comment_count_area')]/span[not(@class)]/text()")
        ).strip()

        try:
            reply = int(reply_text)
        except:
            reply = 0

        if reply > 0:
            threads.append({
                "tid": tid,
                "title": title,
                "reply": reply
            })

    print(f"    ✔ 本页解析到 {len(threads)} 个有回复帖子")
    return threads


# ========== 帖子页 ==========
def parse_thread_detail(tid):
    url = f"{BASE_URL}/thr_res/acode=13/ctrid=1/ctgid=150/bid=2396/tid={tid}/tp=1/"
    html = fetch(url)
    if not html:
        return None

    tree = etree.HTML(html)

    time_text = "".join(tree.xpath("//span[@class='posts']//text()")).strip()
    post_time = parse_time(time_text)
    if not post_time:
        return None

    body = "".join(tree.xpath("//div[@id='threadBody']//text()")).strip()

    comments = []
    for res in tree.xpath("//div[contains(@class,'res_list_article')]"):
        content = "".join(
            res.xpath(".//div[contains(@class,'resbody')]//text()")
        ).strip()

        ctime = "".join(
            res.xpath(".//*[@itemprop='commentTime']//text()")
        ).strip()

        if content:
            comments.append({
                "time": ctime,
                "content": content
            })

    return {
        "tid": tid,
        "post_time": post_time.strftime("%Y-%m-%d %H:%M"),
        "body": body,
        "comments": comments
    }


# ========== 主流程 ==========
def crawl_december(max_pages=5):
    results = []

    for page in range(1, max_pages + 1):
        threads = parse_thread_list(page)
        for t in threads:
            detail = parse_thread_detail(t["tid"])
            if not detail:
                continue

            dt = datetime.strptime(detail["post_time"], "%Y-%m-%d %H:%M")
            if dt.month != 12:
                continue

            results.append({
                "tid": t["tid"],
                "title": t["title"],
                "post_time": detail["post_time"],
                "body": detail["body"],
                "comments": detail["comments"]
            })

            print(f"    ✅ 收录 12 月帖子 {t['tid']}（{len(detail['comments'])} 评论）")
            time.sleep(2)

    return results


# ========== 入口 ==========
if __name__ == "__main__":
    data = crawl_december(max_pages=5)

    with open("bakusai_december.json", "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    print(f"\n🎉 完成：共抓取 {len(data)} 条 12 月帖子")


"tid": "13010381",
    "title": "廣東おじさんの独り言",
    "post_time": "2025-12-04 00:12",
    "body": "ただのつぶやきなので気にしないでくださいお",
    "comments": [
      {
        "time": "2025/12/04 00:23",
        "content": "#41 2025/11/28 15:48\r\n>>40\r\nおまえBKの事か？安価を自レスに刺すなよ笑\r\n\r\n#407 2025/12/03 08:08\r\n>>406\r\n毎日飽きない(笑)Y宫狂いのおじさん\r\n\r\n#39 2025/12/03 16:20最新レス\r\n>>38\r\nどした？お薬切れ？KF市雑談のほとんどを書いてるCO市の自作自演オジサン\r\n\r\n#55 2025/12/03 16:23最新レス\r\n>>49\r\nあちこちのスレ主だろχ市のそいつが\r\n\r\n#412 2025/12/03 16:37\r\n>>411\r\n連投スレ主オッさんお前はCO市住みだろ笑\r\n\r\n#30 2025/12/03 16:48最新レス\r\n>>28>>29\r\n同一人物(笑)χ市って奴か？\r\n\r\n#17 2025/12/03 17:36\r\n>>13\r\n毎日毎日ひでぇ荒らしと1人レスしてらよYNで\r\n\r\n#78 2025/12/03 18:51\r\n>>76\r\nアンカ自演しながら連投χ市の隊？おっさん笑\r\n\r\n#427 2025/12/03 19:00\r\n>>412\r\nCO市が躍起になって更に阿保連投してるw"
      },评论里面只要评论文本，拼接在一起，不要时间，清洗一下数据

{
  "url": "...", 
  "title": "レーダー照射",
  "post_time": "2025-12-09 02:33",
  "body": "を語れます",
  "comments": "アイヤー\n中国 ハニトラ議員 コメンテーターを全部公表したまえ\nパンダも要らんぞ"，“，，，，” 
}









爬取最后回复时间在当前系统月份的帖子（例如 2025 年 12 月），不再往下爬早于本月的帖子。

帖子正文 + 评论，评论最多 100 条。

不抓取没有回复的帖子。

输出格式为：

{
  "url": "...",
  "title": "...",
  "post_time": "...",
  "body": "...",
  "comments": "..."
}









帖子页最多抓 100 条评论，遇到最后回复不是本月就停止，不对，帖子的回复帖有不同的月份，这没关系，只要最后一条最新评论，<li data-tid="13042792">
                                            <span class="thrNumber">5</span>
                    					                    <a href="/thr_res/acode=13/ctrid=1/ctgid=150/bid=2396/tid=13042792/tp=1/" class="thr_status_icon" title="横浜中華街">
                                                横浜中華街
                    </a>
					<span class="thrListContent">
											<span class="thr-posted-ago">
													14時間前												</span>
																<span class="chart_count_area">
							<span class="thrlis_chart_space"><i class="fa fa-bar-chart" aria-hidden="true"></i>
								<span class="chart_balloon newslis_count">閲覧数</span>
							</span>
							<span>132</span>
						</span>
						<span class="comment_count_area newslis_count">
							<span class="thrlis_comment_space"><i class="fa fa-comment-o" aria-hidden="true"></i>
								<span class="comment_balloon newslis_count">レス数</span>
							</span>
							<span>4</span>
						</span>
										</span>
										                                        
				</li>其中<span class="thr-posted-ago">
													14時間前												</span>代表系统时间14小时前，<li data-tid="13000204">
                                            <span class="thrNumber">27</span>
                    					                    <a href="/thr_res/acode=13/ctrid=1/ctgid=150/bid=2396/tid=13000204/tp=1/" class="thr_status_icon" title="中国に対して強気の態度で調子こいてる高市のＢＢＡが">
                                                中国に対して強気の態度で調子こいてる高市のＢＢＡが
                    </a>
					<span class="thrListContent">
											<span class="thr-posted-ago">
													12/11 21:12
												</span>
																<span class="chart_count_area">
							<span class="thrlis_chart_space"><i class="fa fa-bar-chart" aria-hidden="true"></i>
								<span class="chart_balloon newslis_count">閲覧数</span>
							</span>
							<span>348</span>
						</span>
						<span class="comment_count_area newslis_count">
							<span class="thrlis_comment_space"><i class="fa fa-comment-o" aria-hidden="true"></i>
								<span class="comment_balloon newslis_count">レス数</span>
							</span>
							<span>30</span>
						</span>
										</span>
										                                        
				</li>其中<span class="thr-posted-ago">
													12/11 21:12
												</span>代表最后一条回复在12.11，<li data-tid="13003009">
                                            <span class="thrNumber">38</span>
                    					                    <a href="/thr_res/acode=13/ctrid=1/ctgid=150/bid=2396/tid=13003009/tp=2/" class="thr_status_icon" title="温泉にいないんです">
                                                温泉にいないんです
                    </a>
					<span class="thrListContent">
											<span class="thr-posted-ago">
													11/29 19:38
												</span>
																<span class="chart_count_area">
							<span class="thrlis_chart_space"><i class="fa fa-bar-chart" aria-hidden="true"></i>
								<span class="chart_balloon newslis_count">閲覧数</span>
							</span>
							<span>60</span>
						</span>
						<span class="comment_count_area newslis_count">
							<span class="thrlis_comment_space"><i class="fa fa-comment-o" aria-hidden="true"></i>
								<span class="comment_balloon newslis_count">レス数</span>
							</span>
							<span>0</span>
						</span>
										</span>
										                                        
				</li><span class="thr-posted-ago">
													11/29 19:38
												</span>最后一条回复在11.29，到此结束，也就是停在https://bakusai.com/thr_tl/acode=13/ctrid=1/ctgid=150/bid=2396/p=2/界面某一条帖子，不要再往下了，并且这个功能能根据我系统时间的变化而变化，比如我进入26年1月，爬虫爬满最后回复时间26，1所有帖子就结束，停在最后回复时间是25.12的

明白了，你的需求是：

爬列表页帖子，根据最后一条回复时间（<span class="thr-posted-ago">）判断是否属于当月**（即系统时间的年月）**。

列表页只要最后回复不属于当月，就停止往下翻页，不再抓取。
明白了，你的问题是之前抓评论数的逻辑用的是帖子页抓取的评论条数（最多 100 条），或者列表页抓取的 <li> 评论条数，但很多帖子列表页显示的“50”只是系统显示的上限（Bakusai 前端列表页会把大于 50 的评论显示成 50）。你希望抓到 列表页里 <span class="comment_count_area newslis_count"> 中真实评论数。
















少了发帖时间：
import requests
import time
import json
from datetime import datetime, timedelta
from lxml import etree
import re

BASE_URL = "https://bakusai.com"
LIST_URL = "https://bakusai.com/thr_tl/acode=13/ctrid=1/ctgid=150/bid=2396/p={}/"

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
    "Accept-Language": "ja-JP,ja;q=0.9"
}

session = requests.Session()
session.headers.update(HEADERS)

# ========== 请求 ==========
def fetch(url):
    try:
        r = session.get(url, timeout=20)
        r.raise_for_status()
        return r.content
    except Exception as e:
        print("⚠️ 请求失败：", e)
        return None

# ========== 清洗评论文本 ==========
def clean_comments_text(comments_list):
    all_text = []
    for c in comments_list:
        text = c["content"]
        text = re.sub(r'#\d+\s*[\d/:\s]*', '', text)  # 去掉 #数字、日期
        text = re.sub(r'>>\d+', '', text)             # 去掉引用
        text = text.replace('\r', '').replace('\n', ' ')
        text = re.sub(r'\s+', ' ', text).strip()
        if text:
            all_text.append(text)
    return '\n'.join(all_text)

# ========== 列表页解析 ==========
def parse_last_reply_time(text):
    text = text.strip()
    now = datetime.now()
    if "時間前" in text:
        h = int(re.search(r'(\d+)時間前', text).group(1))
        return now - timedelta(hours=h)
    elif "分前" in text:
        m = int(re.search(r'(\d+)分前', text).group(1))
        return now - timedelta(minutes=m)
    else:  # 12/11 21:12 形式
        try:
            dt = datetime.strptime(text, "%m/%d %H:%M")
            return dt.replace(year=now.year)
        except:
            return None

def parse_thread_list(page, current_year, current_month):
    print(f"📄 正在抓列表页 {page}")
    html = fetch(LIST_URL.format(page))
    if not html:
        return [], True

    tree = etree.HTML(html)
    threads = []
    stop = False

    for li in tree.xpath("//li[@data-tid]"):
        tid = li.get("data-tid")
        title = "".join(li.xpath(".//a[contains(@class,'thr_status_icon')]//text()")).strip()

        # 列表页真实评论数
        comment_count_text = li.xpath(".//span[contains(@class,'comment_count_area')]/span[last()]/text()")
        try:
            comment_count = int(comment_count_text[0].strip())
        except:
            comment_count = 0

        # 最后一条回复时间
        last_reply_text = "".join(li.xpath(".//span[@class='thr-posted-ago']//text()")).strip()
        last_reply_time = parse_last_reply_time(last_reply_text)
        if not last_reply_time:
            continue

        # 停止条件：最后回复不是当月
        if last_reply_time.year != current_year or last_reply_time.month != current_month:
            stop = True
            continue

        if comment_count == 0:
            continue

        threads.append({
            "tid": tid,
            "title": title,
            "url": f"{BASE_URL}/thr_res/acode=13/ctrid=1/ctgid=150/bid=2396/tid={tid}/tp=1/",
            "comment_count": comment_count
        })

    print(f"    ✔ 本页解析到 {len(threads)} 个本月有回复帖子")
    return threads, stop

# ========== 帖子页解析 ==========
def parse_thread_detail(thread):
    html = fetch(thread["url"])
    if not html:
        return None

    tree = etree.HTML(html)
    # 帖子正文
    body = "".join(tree.xpath("//div[@id='threadBody']//text()")).strip()

    # 评论
    comments = []
    for idx, res in enumerate(tree.xpath("//div[contains(@class,'resbody')]")):
        if idx >= 100:  # 最多抓 100 条评论
            break
        content = "".join(res.xpath(".//text()")).strip()
        if content:
            comments.append({"content": content})

    comments_text = clean_comments_text(comments)
    return {
        "url": thread["url"],
        "title": thread["title"],
        "comment_count": thread["comment_count"],
        "body": body,
        "comments": comments_text
    }

# ========== 主流程 ==========
def crawl_current_month(max_pages=50):
    results = []
    now = datetime.now()
    current_year = now.year
    current_month = now.month

    for page in range(1, max_pages + 1):
        threads, stop = parse_thread_list(page, current_year, current_month)
        for t in threads:
            detail = parse_thread_detail(t)
            if not detail:
                continue
            results.append(detail)
            print(f"    ✅ 收录帖子 {t['tid']}（评论数: {t['comment_count']}）")
            time.sleep(1)

        if stop:
            print("📌 已到当月最后回复帖子，停止翻页")
            break
        time.sleep(2)

    return results

# ========== 入口 ==========
if __name__ == "__main__":
    data = crawl_current_month(max_pages=50)

    with open("bakusai_current_month.json", "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    print(f"\n🎉 完成：共抓取 {len(data)} 条本月帖子")



加上发帖时间：
import requests
import time
import json
from datetime import datetime, timedelta
from lxml import etree
import re

BASE_URL = "https://bakusai.com"
LIST_URL = "https://bakusai.com/thr_tl/acode=13/ctrid=1/ctgid=150/bid=2396/p={}/"

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
    "Accept-Language": "ja-JP,ja;q=0.9"
}

session = requests.Session()
session.headers.update(HEADERS)

# ========== 请求 ==========
def fetch(url):
    try:
        r = session.get(url, timeout=20)
        r.raise_for_status()
        return r.content  # 返回 bytes，避免 encoding declaration 报错
    except Exception as e:
        print("⚠️ 请求失败：", e)
        return None

# ========== 清洗评论文本 ==========
def clean_comments_text(comments_list):
    all_text = []
    for c in comments_list:
        text = c["content"]
        text = re.sub(r'#\d+\s*[\d/:\s]*', '', text)  # 去掉 #数字、日期
        text = re.sub(r'>>\d+', '', text)             # 去掉引用
        text = text.replace('\r', '').replace('\n', ' ')
        text = re.sub(r'\s+', ' ', text).strip()
        if text:
            all_text.append(text)
    return '\n'.join(all_text)

# ========== 解析列表页最后回复时间 ==========
def parse_last_reply_time(text):
    text = text.strip()
    now = datetime.now()
    if "時間前" in text:
        h = int(re.search(r'(\d+)時間前', text).group(1))
        return now - timedelta(hours=h)
    elif "分前" in text:
        m = int(re.search(r'(\d+)分前', text).group(1))
        return now - timedelta(minutes=m)
    else:  # 12/11 21:12 形式
        try:
            dt = datetime.strptime(text, "%m/%d %H:%M")
            return dt.replace(year=now.year)
        except:
            return None

# ========== 解析列表页 ==========
def parse_thread_list(page, current_year, current_month):
    print(f"📄 正在抓列表页 {page}")
    html = fetch(LIST_URL.format(page))
    if not html:
        return [], True

    tree = etree.HTML(html)
    threads = []
    stop = False

    for li in tree.xpath("//li[@data-tid]"):
        tid = li.get("data-tid")
        title = "".join(li.xpath(".//a[contains(@class,'thr_status_icon')]//text()")).strip()

        # 列表页真实评论数
        comment_count_text = li.xpath(".//span[contains(@class,'comment_count_area')]/span[last()]/text()")
        try:
            comment_count = int(comment_count_text[0].strip())
        except:
            comment_count = 0

        # 最后一条回复时间
        last_reply_text = "".join(li.xpath(".//span[@class='thr-posted-ago']//text()")).strip()
        last_reply_time = parse_last_reply_time(last_reply_text)
        if not last_reply_time:
            continue

        # 停止条件：最后回复不是当月
        if last_reply_time.year != current_year or last_reply_time.month != current_month:
            stop = True
            continue

        if comment_count == 0:
            continue

        threads.append({
            "tid": tid,
            "title": title,
            "url": f"{BASE_URL}/thr_res/acode=13/ctrid=1/ctgid=150/bid=2396/tid={tid}/tp=1/",
            "comment_count": comment_count
        })

    print(f"    ✔ 本页解析到 {len(threads)} 个本月有回复帖子")
    return threads, stop

# ========== 解析帖子页 ==========
def parse_thread_detail(thread):
    html = fetch(thread["url"])
    if not html:
        return None

    tree = etree.HTML(html)

    # 发帖时间
    post_time_text = tree.xpath("//span[@class='posts' and @itemprop='datePublished']/text()")
    if post_time_text:
        post_time_text = post_time_text[0].strip()
        try:
            post_time = datetime.strptime(post_time_text, "%Y/%m/%d %H:%M").strftime("%Y-%m-%d %H:%M:%S")
        except:
            post_time = ""
    else:
        post_time = ""

    # 帖子正文
    body = "".join(tree.xpath("//div[@id='threadBody']//text()")).strip()

    # 评论
    comments = []
    for idx, res in enumerate(tree.xpath("//div[contains(@class,'resbody')]")):
        if idx >= 100:  # 最多抓 100 条评论
            break
        content = "".join(res.xpath(".//text()")).strip()
        if content:
            comments.append({"content": content})

    comments_text = clean_comments_text(comments)

    return {
        "url": thread["url"],
        "title": thread["title"],
        "comment_count": thread["comment_count"],
        "post_time": post_time,
        "body": body,
        "comments": comments_text
    }

# ========== 主流程 ==========
def crawl_current_month(max_pages=50):
    results = []
    now = datetime.now()
    current_year = now.year
    current_month = now.month

    for page in range(1, max_pages + 1):
        threads, stop = parse_thread_list(page, current_year, current_month)
        for t in threads:
            detail = parse_thread_detail(t)
            if not detail:
                continue
            results.append(detail)
            print(f"    ✅ 收录帖子 {t['tid']}（评论数: {t['comment_count']}）")
            time.sleep(1)

        if stop:
            print("📌 已到当月最后回复帖子，停止翻页")
            break
        time.sleep(2)

    return results

# ========== 入口 ==========
if __name__ == "__main__":
    data = crawl_current_month(max_pages=50)

    with open("bakusai_current_month.json", "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    print(f"\n🎉 完成：共抓取 {len(data)} 条本月帖子")

