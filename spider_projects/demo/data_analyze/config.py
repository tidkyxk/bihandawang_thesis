import os
import json
import time
from openai import OpenAI


# ===============================
# 1. åˆå§‹åŒ– DeepSeek å®¢æˆ·ç«¯
# ===============================
def init_client():
    """åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼Œæ”¯æŒå¤šç§æ–¹å¼è·å–APIå¯†é’¥"""
    # å°è¯•ä»ä¸åŒæ¥æºè·å–APIå¯†é’¥
    api_key = None

    # 1. ç¯å¢ƒå˜é‡
    api_key = os.getenv("DEEPSEEK_API_KEY")

    # 2. é…ç½®æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if not api_key:
        try:
            from config_secret import DEEPSEEK_API_KEY
            api_key = DEEPSEEK_API_KEY
        except ImportError:
            pass

    # 3. ç”¨æˆ·è¾“å…¥ï¼ˆå¦‚æœæ²¡æœ‰é…ç½®ï¼‰
    if not api_key:
        print("=" * 40)
        print("ğŸ“ è¯·è¾“å…¥DeepSeek APIå¯†é’¥")
        print("=" * 40)
        api_key = input("APIå¯†é’¥: ").strip()

        # è¯¢é—®æ˜¯å¦ä¿å­˜
        save = input("æ˜¯å¦ä¿å­˜åˆ°æœ¬åœ°é…ç½®æ–‡ä»¶ä»¥ä¾¿ä¸‹æ¬¡ä½¿ç”¨ï¼Ÿ(y/n): ").lower()
        if save == 'y':
            try:
                with open('config_secret.py', 'w', encoding='utf-8') as f:
                    f.write(f'DEEPSEEK_API_KEY = "{api_key}"\n')
                print("âœ… APIå¯†é’¥å·²ä¿å­˜åˆ° config_secret.py")
            except Exception as e:
                print(f"âŒ ä¿å­˜å¤±è´¥: {e}")

    if not api_key:
        raise ValueError("æœªæä¾›APIå¯†é’¥")

    return OpenAI(
        api_key=api_key,
        base_url="https://api.deepseek.com"
    )


client = init_client()


# ===============================
# 2. æƒ…æ„Ÿåˆ†æå‡½æ•°
# ===============================
def analyze_sentiment(text, target_name):
    """
    text: å¾…åˆ†ææ–‡æœ¬
    target_name: 'æ–°é—»æ­£æ–‡' æˆ– 'æ–°é—»è¯„è®ºåŒº'
    è¿”å›ï¼šdict
    """

    if not text.strip():
        return {
            "sentiment": "ä¸­æ€§",
            "reason": "æ–‡æœ¬å†…å®¹ä¸ºç©ºæˆ–ä¿¡æ¯é‡ä¸è¶³ï¼Œæ— æ³•ä½“ç°æ˜æ˜¾æƒ…æ„Ÿå€¾å‘ã€‚"
        }

    prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼ã€å®¢è§‚çš„æ–‡æœ¬æƒ…æ„Ÿåˆ†ææ¨¡å‹ã€‚

è¯·åˆ†æä»¥ä¸‹ã€{target_name}ã€‘çš„æ•´ä½“æƒ…æ„Ÿå€¾å‘ã€‚

è¦æ±‚ï¼š
1. æƒ…æ„Ÿåªèƒ½æ˜¯ï¼šç§¯æ / ä¸­æ€§ / æ¶ˆæ
2. æ ¹æ®æ–‡æœ¬æ•´ä½“è¯­æ°”ã€ç”¨è¯å’Œè¡¨è¾¾åˆ¤æ–­ï¼Œä¸è¿›è¡Œäº‹å®è¯„ä»·
3. ä½¿ç”¨ç®€ä½“ä¸­æ–‡
4. è¾“å‡ºå¿…é¡»æ˜¯ JSON æ ¼å¼ï¼Œä»…åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
   - sentiment
   - reason

æ–‡æœ¬å¦‚ä¸‹ï¼š
{text}
"""

    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "user", "content": prompt}
            ],
            temperature=0
        )

        result_text = response.choices[0].message.content

        # è§£æJSON
        try:
            return json.loads(result_text)
        except json.JSONDecodeError:
            # å¦‚æœè¿”å›çš„ä¸æ˜¯JSONï¼Œå°è¯•æå–æƒ…æ„Ÿ
            if "ç§¯æ" in result_text:
                sentiment = "ç§¯æ"
            elif "æ¶ˆæ" in result_text:
                sentiment = "æ¶ˆæ"
            else:
                sentiment = "ä¸­æ€§"

            return {
                "sentiment": sentiment,
                "reason": result_text[:200] + "..." if len(result_text) > 200 else result_text
            }

    except Exception as e:
        print(f"âš ï¸  æƒ…æ„Ÿåˆ†æå¤±è´¥: {e}")
        return {
            "sentiment": "æœªçŸ¥",
            "reason": f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"
        }


# ===============================
# 3. åˆ†æå•æ¡æ–°é—»
# ===============================
def analyze_single_news(news_item):
    article_text = news_item.get("article_text", "")
    comments = news_item.get("comments", [])

    # å°†è¯„è®ºåˆå¹¶ä¸ºä¸€æ®µæ–‡æœ¬
    comment_text = "\n".join([f"[è¯„è®º{i + 1}] {comment}" for i, comment in enumerate(comments)])

    print(f"ğŸ” åˆ†ææ–°é—»: {news_item.get('title', 'æ— æ ‡é¢˜')[:50]}...")

    article_sentiment = analyze_sentiment(article_text, "æ–°é—»æ­£æ–‡")
    comment_sentiment = analyze_sentiment(comment_text, "æ–°é—»è¯„è®ºåŒº") if comment_text else {
        "sentiment": "æ— è¯„è®º",
        "reason": "è¯¥æ–°é—»æš‚æ— ç”¨æˆ·è¯„è®º"
    }

    # è®¡ç®—ä¸€è‡´æ€§
    alignment = "ä¸€è‡´" if article_sentiment["sentiment"] == comment_sentiment["sentiment"] else "ä¸ä¸€è‡´"

    return {
        "url": news_item.get("url", ""),
        "title": news_item.get("title", ""),
        "article_sentiment": article_sentiment,
        "comment_sentiment": comment_sentiment,
        "sentiment_alignment": alignment,
        "total_comments": len(comments)
    }


# ===============================
# 4. æ‰¹é‡åˆ†æ JSON æ–‡ä»¶
# ===============================
def analyze_news_file(input_path, output_path, sleep_time=1, max_items=None):
    """æ‰¹é‡åˆ†ææ–°é—»"""

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(input_path):
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")
        return

    with open(input_path, "r", encoding="utf-8") as f:
        news_list = json.load(f)

    # é™åˆ¶åˆ†ææ•°é‡
    if max_items and max_items < len(news_list):
        news_list = news_list[:max_items]
        print(f"ğŸ“Š å°†åˆ†æå‰ {max_items} æ¡æ–°é—»ï¼ˆå…± {len(news_list)} æ¡ï¼‰")

    results = []

    print(f"ğŸš€ å¼€å§‹åˆ†æ {len(news_list)} æ¡æ–°é—»...")
    print("=" * 60)

    for idx, news in enumerate(news_list, 1):
        print(f"[{idx}/{len(news_list)}] ", end="")
        try:
            result = analyze_single_news(news)
            results.append(result)

            # æ˜¾ç¤ºç®€è¦ç»“æœ
            print(f"âœ… æ–°é—»: {result['article_sentiment']['sentiment']} | "
                  f"è¯„è®º: {result['comment_sentiment']['sentiment']} | "
                  f"ä¸€è‡´æ€§: {result['sentiment_alignment']}")

            time.sleep(sleep_time)  # é˜²æ­¢è¯·æ±‚è¿‡å¿«
        except Exception as e:
            print(f"âŒ åˆ†æå¤±è´¥: {news.get('title', 'æ— æ ‡é¢˜')} - {e}")
            results.append({
                "error": str(e),
                "url": news.get("url", ""),
                "title": news.get("title", "")
            })

    # ä¿å­˜ç»“æœ
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    # ç”Ÿæˆæ‘˜è¦
    print("\n" + "=" * 60)
    print("ğŸ“Š åˆ†ææ‘˜è¦")
    print("=" * 60)

    successful = sum(1 for r in results if "error" not in r)
    print(f"âœ… æˆåŠŸåˆ†æ: {successful}/{len(news_list)} æ¡æ–°é—»")

    # ç»Ÿè®¡æƒ…æ„Ÿåˆ†å¸ƒ
    article_sentiments = {"ç§¯æ": 0, "ä¸­æ€§": 0, "æ¶ˆæ": 0, "æ— è¯„è®º": 0, "æœªçŸ¥": 0}
    comment_sentiments = {"ç§¯æ": 0, "ä¸­æ€§": 0, "æ¶ˆæ": 0, "æ— è¯„è®º": 0, "æœªçŸ¥": 0}
    alignments = {"ä¸€è‡´": 0, "ä¸ä¸€è‡´": 0}

    for result in results:
        if "error" in result:
            continue

        article_sent = result["article_sentiment"]["sentiment"]
        comment_sent = result["comment_sentiment"]["sentiment"]
        alignment = result["sentiment_alignment"]

        if article_sent in article_sentiments:
            article_sentiments[article_sent] += 1

        if comment_sent in comment_sentiments:
            comment_sentiments[comment_sent] += 1

        if alignment in alignments:
            alignments[alignment] += 1

    print("\nğŸ“° æ–°é—»æƒ…æ„Ÿåˆ†å¸ƒ:")
    for sent, count in article_sentiments.items():
        if count > 0:
            print(f"  {sent}: {count} æ¡")

    print("\nğŸ’¬ è¯„è®ºæƒ…æ„Ÿåˆ†å¸ƒ:")
    for sent, count in comment_sentiments.items():
        if count > 0:
            print(f"  {sent}: {count} æ¡")

    print(f"\nğŸ”„ æƒ…æ„Ÿä¸€è‡´æ€§: ä¸€è‡´ {alignments['ä¸€è‡´']} æ¡ | ä¸ä¸€è‡´ {alignments['ä¸ä¸€è‡´']} æ¡")

    print(f"\nğŸ’¾ åˆ†æå®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š{output_path}")


# ===============================
# 5. ä¸»ç¨‹åºå…¥å£
# ===============================
if __name__ == "__main__":
    import sys

    # ç®€å•å‘½ä»¤è¡Œå‚æ•°
    max_items = None
    if len(sys.argv) > 1:
        try:
            max_items = int(sys.argv[1])
            print(f"ğŸ”§ é™åˆ¶åˆ†ææ•°é‡: {max_items} æ¡")
        except ValueError:
            pass

    # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œç»™ç”¨æˆ·æç¤º
    if not os.path.exists("config_secret.py"):
        print("ğŸ’¡ æç¤ºï¼šå¯ä»¥åˆ›å»º config_secret.py æ–‡ä»¶ä¿å­˜APIå¯†é’¥")
        print("     å†…å®¹ï¼šDEEPSEEK_API_KEY = 'your_key_here'")
        print("     å°†æ­¤æ–‡ä»¶æ·»åŠ åˆ° .gitignore ä¸­é¿å…ä¸Šä¼ \n")

    analyze_news_file(
        input_path="bakusai_china_news.json",
        output_path="deepseek_news_sentiment_result.json",
        sleep_time=1,
        max_items=max_items
    )